# For more information on configuration, see:
#   * Official English Documentation: http://nginx.org/en/docs/
#   * Official Russian Documentation: http://nginx.org/ru/docs/
#User from which will be launched NGINX
 user  nginx;
#This number should be, at maximum, the number of CPU cores on your system. 
# You could check this parameter: grep processor /proc/cpuinfo | wc -l
# It controls number of worker processes Nginx is running.
 worker_processes 4; #auto;
# Reduces the number of system calls gettimeofday (), which leads to increased productivity
 timer_resolution 100ms;	
#
 worker_cpu_affinity 0001 0010 0100 1000;
# Priority of worker for NGINX: 
 worker_priority  -5;
# Number of file descriptors used for Nginx. 
#testing issue like "1172 open socket #36 left in connection 19"
 worker_rlimit_nofile 100000; # 
# Path of lock_file:
 lock_file /run/lock/nginx.lock;
#File with errors
# You couls use: [ debug | info | notice | warn | error | crit ]; Fully disable log errors: error_log /dev/null crit;
 error_log  /var/log/nginx/error.log; # can use [/var/log/nginx/error.log warn buffer=16k;]
# Path of PID: 
 pid        /run/nginx.pid;
#
 events { 
	 # Determines how many clients will be served by each worker process; [Default is 768]
    	  worker_connections 8192;  #4096; #1024;
	 # You can see the available event-models and how you can activate
  	 # it at the ./configure -> http://wiki.nginx.org/NginxOptimizations
  	 #
	 # use [ kqueue | rtsig | epoll | /dev/poll | select | poll ] ;
	 # Linux - epoll; FreeBSD - kqueue
  	  use epoll;
         # multi_accept tries to accept() as many connections as
  	 # possible after nginx gets notification about a new connection.
  	 # default: off
  	  multi_accept on;
  	 # If a worker process does not have accept mutex it will
  	 # try to aquire it at least after this delay.
  	 # default: 500ms
  	  accept_mutex_delay 50ms;
	   #accept_mutex off;
	}
#
 http {
       # Add MiMe types		
	include mime.types;
         #include       /etc/nginx/mime.types;
       ############################################################################### 
       #					Log format			      #
       ############################################################################### 
       #log format for main
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';
       #log format for download
        log_format download  '$remote_addr - $remote_user [$time_local] '
                             '"$request" $status $bytes_sent '
                             '"$http_referer" "$http_user_agent" '
                             '"$http_range" "$sent_http_content_range"';
       #log format for cache
	log_format cache '$remote_addr - $remote_user [$time_local] "$request" '
                         '$status $upstream_cache_status $body_bytes_sent "$http_referer" '
                         '"$http_user_agent" "$http_x_forwarded_for"'; 
	###############################################################################
        ## Hostname Options
	#If server_name_in_redirect is on, then Nginx will use the first value
	#of the server_name directive for redirects. If server_name_in_redirect
	#is off, then nginx will use the requested Host header.
	#http://wiki.nginx.org/NginxHttpCoreModule#server_name_in_redirect
         server_name_in_redirect off; #on;
        #The size of the hash for the domain name. 
	#server_names_hash_bucket_size controls the maximum length of a virtual host entry (ie the length of the domain name).
	 server_names_hash_bucket_size 512;
	#
         server_names_hash_max_size 2048;	
        #SIZE LIMITS#####################
        #Data Size Accepted POST request 
	#The directive sets the maximum allowable size of the client request body, indicated by the line "Content-Length" header in the request. 
	#If greater than the specified size, the client gets the error "Request Entity Too Large" (413). 
	#It should be borne in mind that browsers can not correctly display this error. Fix issue "413 Request Entity Too Large"
	# Default : [client_max_body_size 1m;]	 
	 client_max_body_size 80M;
	#Sets buffer size for reading client request header. For most requests, a buffer of 1K bytes is enough. 
	#However, if a request includes long cookies, or comes from a WAP client, it may not fit into 1K
        # Similar to the previous directive, only instead it handles the client header size. 
        #For all intents and purposes, 1K is usually a decent size for this directive.	
	# default: [client_header_buffer_size 1k;]
         client_header_buffer_size 1M;
	#Sets buffer size for reading client request body. In case the request body is larger than the buffer, the whole body or only its part is written to a temporary file. 
	#By default, buffer size is equal to two memory pages. This is 8K on x86, other 32-bit platforms, and x86-64. It is usually 16K on other 64-bit platforms.
        # This handles the client buffer size, meaning any POST actions sent to Nginx. POST actions are typically form submissions.	
         client_body_buffer_size 32k;	 
        # The maximum number and size of buffers for large client headers.	
	#Sets the maximum number and size of buffers used for reading large client request header. 
	#A request line cannot exceed the size of one buffer, or the 414 (Request-URI Too Large) error is returned to the client. 
	#A request header field cannot exceed the size of one buffer as well, or the 400 (Bad Request) error is returned to the client. 
	#Buffers are allocated only on demand. By default, the buffer size is equal to 8K bytes. 
	#If after the end of request processing a connection is transitioned into the keep-alive state, these buffers are released.
         large_client_header_buffers 32 128k; 
        # TIMEOUTS
	#Defines a timeout for reading client request body. 
	#The timeout is set only for a period between two successive read operations, not for the transmission of the whole request body. 
	#If a client does not transmit anything within this time, the 408 (Request Time-out) error is returned to the client.
        #Default: [client_body_timeout 60s;] 
	 client_body_timeout 3m;
	 #client_body_timeout 10;
	#Defines a timeout for reading client request header.
	# If a client does not transmit the entire header within this time, the 408 (Request Time-out) error is returned to the client.
	# Default: [client_header_timeout 60s;]
         client_header_timeout 3m;
	#Sets a timeout for transmitting a response to the client. 
	#The timeout is set only between two successive write operations, not for the transmission of the whole response.
	#If the client does not receive anything within this time, the connection is closed.
        # if client stop responding, free up memory.
	# Default: [send_timeout 60s;] 
	 send_timeout 3m;
	 #send_timeout 2;
        # The first parameter assigns the timeout for keep-alive connections
        # with the client. The server will close connections after this time.
        # The optional second parameter assigns the time value in the header
        # Keep-Alive:meout=time of the response. This header can convince
        # some browsers to close the connection, so that the server does not
        # have to. Without this parameter, nginx does not send a Keep-Alive
        # header (though this is not what makes a connection "keep-alive").
        # The parameters can differ from each other.
        # Notes on how browsers handle the Keep-Alive header:
        # MSIE and Opera ignore the "Keep-Alive: timeout=<N>" header.
        # MSIE keeps the connection alive for about 60-65 seconds, then sends a TCP RST.
        # Opera keeps the connection alive for a long time.
        # Mozilla keeps the connection alive for N plus about 1-10 seconds.
        # Konqueror keeps the connection alive for about N seconds.
        # server will close connection after this time
        # default: keepalive_timeout 75
         keepalive_timeout 30;  #75 20;
	#Sets the maximum number of requests that can be served through one keep-alive connection. 
	# After the maximum number of requests are made, the connection is closed.
         keepalive_requests 1000;   
	# allow all browsers to use keepalive connections
	 keepalive_disable         none;
        # When lingering_close is in effect, this directive specifies the maximum time during which nginx will process (read and ignore) additional data coming from a client. 
	#After that, the connection will be closed, even if there will be more data.
	# Default: [lingering_time 30s;]
         lingering_time     30;
	#When lingering_close is in effect, this directive specifies the maximum waiting time for more client data to arrive.
	#If data are not received during this time, the connection is closed.
	#Otherwise, the data are read and ignored, and nginx starts waiting for more data again. 
	#The “wait-read-ignore” cycle is repeated, but no longer than specified by the lingering_time directive.
	#Default: [lingering_timeout 5s;]
         lingering_timeout  10;
	#Enables or disables resetting timed out connections. 
	#The reset is performed as follows. 
	#Before closing a socket, the SO_LINGER option is set on it with a timeout value of 0. 
	#When the socket is closed, TCP RST is sent to the client, and all memory occupied by this socket is released. 
	#This helps avoid keeping an already closed socket with filled buffers in a FIN_WAIT1 state for a long time.
        # Reset lingering timed out connections. Deflect DDoS.
        # allow the server to close connection on non responding client, this will free up memory
	# Default: [reset_timedout_connection off;]
	 reset_timedout_connection on;
        #Adds the specified charset to the “Content-Type” response header field. 
	#If this charset is different from the charset specified in the source_charset directive, a conversion is performed.
	#The parameter off cancels the addition of charset to the “Content-Type” response header field.
	#Default: [charset off;]
         charset utf-8;
	 #source_charset utf-8; # same value as "charset"
	#Defines the default MIME type of a response. 
	#Mapping of file name extensions to MIME types can be set with the types directive.
	 default_type  application/octet-stream;
	#
        # Update charset_types due to updated mime.types
         charset_types text/xml text/plain text/vnd.wap.wml application/x-javascript application/rss+xml text/css application/javascript application/json;
	#Defines files that will be used as an index. 
	#The file name can contain variables. 
	#Files are checked in the specified order. 
	#The last element of the list can be a file with an absolute path
         index index.php index.htm index.html iredirect.php;
	#Controls whether header fields with invalid names should be ignored. 
	#Valid names are composed of English letters, digits, hyphens, and possibly underscores (as controlled by the underscores_in_headers directive).
	# Default: [ignore_invalid_headers on;]
	# Just for SSL, maybe
         ignore_invalid_headers on;
	#Enables or disables doing several redirects using the error_page directive.
	#The number of such redirects is limited.
	# Default: [recursive_error_pages off;]
         recursive_error_pages on;
	#Sets the maximum size of the types hash tables. 
	#The details of setting up hash tables are provided in a separate document.
	#Default: [types_hash_max_size 1024;]
         types_hash_max_size 4096;
	#Sets the number and size of the buffers used for reading a response from a disk.       
        #Expanding buffer returns
	#Default: [output_buffers 2 32k;] 
	 output_buffers   10 128k;
	#If possible, the transmission of client data will be postponed until nginx has at least size bytes of data to send. 
	#The zero value disables postponing data transmission.
        # Buffer is used to return the processed data 
	#Default: [postpone_output 1460;]
	 postpone_output  1500; 
	#kernel read head set to the output_buffers
	#Sets the amount of pre-reading for the kernel when working with file.
	#Default: [read_ahead 0;]
	 read_ahead                512K;
	#When set to a non-zero value, limits the amount of data that can be transferred in a single sendfile() call. 
	#Without the limit, one fast connection may seize the worker process entirely.
        # Limit the size of the segment being sent for one lockable return
	# Default: [endfile_max_chunk 0;]
	 sendfile_max_chunk  512;	  
        # Hide the Nginx version number.
	#Default: [server_tokens on;]
         server_tokens  off;
        # Tell Nginx not to send out partial frames; this increases throughput
        # since TCP frames are filled up before being sent out. (adds TCP_CORK)
        # send headers in one peace, its better then sending them one by one
	#Default: [tcp_nopush off;]
	 tcp_nopush      on;
        # Tell Nginx to enable the Nagle buffering algorithm for TCP packets, which
        # collates several smaller packets together into one larger packet, thus saving
        # bandwidth at the cost of a nearly imperceptible increase to latency. (removes TCP_NODELAY)
        # don't buffer data sent, good for small data bursts in real time
	#Default: [tcp_nodelay on;]
	 tcp_nodelay     on;
	#If the directive is set to a non-zero value, nginx will try to minimize the number of send operations on client sockets 
	#by using either NOTE_LOWAT flag of the kqueue method or the SO_SNDLOWAT socket option. 
	#In both cases the specified size is used.
	#Default: [send_lowat 0;]
	 #send_lowat      12000;
        # Use sendfile() syscall to speed up I/O operations and speed up
        # static file serving.
        # copies data between one FD and other from within the kernel
        # faster then read() + write() 
	#Default: [sendfile off;]
	 sendfile on;
	###############################################################################        
	#				SSL SETTINGS     	     		      #
	###############################################################################
	# Use a SSL/TLS cache for SSL session resume. This needs to be
        # here (in this context, for session resumption to work. See this
        # thread on the Nginx mailing list:
        # http://nginx.org/pipermail/nginx/2010-November/023736.html.
	#ssl_session_cache off | none | [builtin[:size]] [shared:name:size];
	#Sets the types and sizes of caches that store session parameters. A cache can be of any of the following types:
	#off - the use of a session cache is strictly prohibited: nginx explicitly tells a client that sessions may not be reused.
	#none - the use of a session cache is gently disallowed: nginx tells a client that sessions may be reused, but does not actually store session parameters in the cache.
	#builtin - a cache built in OpenSSL; used by one worker process only. The cache size is specified in sessions. 
	#If size is not given, it is equal to 20480 sessions. Use of the built-in cache can cause memory fragmentation.
	#shared - a cache shared between all worker processes. 
	#The cache size is specified in bytes; one megabyte can store about 4000 sessions. 
	#Each shared cache should have an arbitrary name. A cache with the same name can be used in several virtual servers.
	#Default: [ssl_session_cache none;]
	 ssl_session_cache     builtin:1000          shared:SSL:10m; # but for better reason need to use just shared:SSL:10m;
	#Specifies a time during which a client may reuse the session parameters stored in a cache.
	#Default: [ssl_session_timeout 5m;]
	 ssl_session_timeout             1d;
	#Use protocols
	 ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
	#Specifies that server ciphers should be preferred over client ciphers when using the SSLv3 and TLS protocols.
	#Default: [ssl_prefer_server_ciphers off;]
         ssl_prefer_server_ciphers on;
	## ciphers chosen and ordered for mix of performance, interoperability and security 
        #AES256+EECDH - Forward Secrecy
	#AES128-SHA256:AES256-SHA - OCSP stapling
        #!EXPORT - Strict Transport Security (HSTS)
        #        -  SNI support.
        ##IGNORED- !MD5:!PSK:!RC4:!DSS:!SRP:!EXP:!LOW:!3DES
	#Specifies the enabled ciphers. The ciphers are specified in the format understood by the OpenSSL library.
	 ssl_ciphers "AES256+EECDH:AES128-SHA256:AES256-SHA:AES128-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4";   
	#
	# Use Google DNS
	 resolver 8.8.8.8 8.8.4.4 valid=300s;
	 resolver_timeout 15s;
	# OCSP (Online Certificate Status Protocol) is a protocol for checking if a SSL certificate has been revoked
	#Enables or disables stapling of OCSP responses by the server
	#Default: [ssl_stapling off;]
         ssl_stapling on;
	#Enables or disables verification of OCSP responses by the server.
	#For verification to work, the certificate of the server certificate issuer, the root certificate, 
	#and all intermediate certificates should be configured as trusted using the ssl_trusted_certificate directive.
	#Default: [ssl_stapling_verify off;]
	 ssl_stapling_verify on; # Requires nginx => 1.3.7
	#Enables verification of client certificates. The verification result is stored in the $ssl_client_verify variable.
	#ssl_verify_client on | off | optional | optional_no_ca;
	#Default: [ssl_verify_client off;]
	 ssl_verify_client off;
	#Sets the verification depth in the client certificates chain.
	#Default: [ssl_verify_depth 1;]
	 ssl_verify_depth 1;
        # Enable clickjacking protection in modern browsers. Available in
        # IE8 also. See
        # https://developer.mozilla.org/en/The_X-FRAME-OPTIONS_response_header
         add_header X-Frame-Options DENY; #SAMEORIGIN;
        # when serving user-supplied content, include a X-Content-Type-Options: nosniff header along with the Content-Type: header,
        # to disable content-type sniffing on some browsers.
        # https://www.owasp.org/index.php/List_of_useful_HTTP_headers
        # currently suppoorted in IE > 8 http://blogs.msdn.com/b/ie/archive/2008/09/02/ie8-security-part-vi-beta-2-update.aspx
        # http://msdn.microsoft.com/en-us/library/ie/gg622941(v=vs.85).aspx
        # 'soon' on Firefox https://bugzilla.mozilla.org/show_bug.cgi?id=471020
         add_header X-Content-Type-Options nosniff;
        # This header enables the Cross-site scripting (XSS) filter built into most recent web browsers.
        # It's usually enabled by default anyway, so the role of this header is to re-enable the filter for
        # this particular website if it was disabled by the user.
        # https://www.owasp.org/index.php/List_of_useful_HTTP_headers
         add_header X-XSS-Protection "1; mode=block";
        # with Content Security Policy (CSP) enabled(and a browser that supports it(http://caniuse.com/#feat=contentsecuritypolicy),
        # you can tell the browser that it can only download content from the domains you explicitly allow
        # http://www.html5rocks.com/en/tutorials/security/content-security-policy/
        # https://www.owasp.org/index.php/Content_Security_Policy
        # I need to change our application code so we can increase security by disabling 'unsafe-inline' 'unsafe-eval'
        # directives for css and js(if you have inline css or js, you will need to keep it too).
        # more: http://www.html5rocks.com/en/tutorials/security/content-security-policy/#inline-code-considered-harmful
         add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://ssl.google-analytics.com https://assets.zendesk.com https://connect.facebook.net; img-src 'self' https://ssl.google-analytics.com https://s-static.ak.facebook.com https://assets.zendesk.com; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com https://assets.zendesk.com; font-src 'self' https://themes.googleusercontent.com; frame-src https://assets.zendesk.com https://www.facebook.com https://s-static.ak.facebook.com https://tautt.zendesk.com; object-src 'none'";
        # Define a zone for limiting the number of simultaneous
        # connections nginx accepts. 1m means 32000 simultaneous
        # sessions. We need to define for each server the limit_conn
        # value refering to this or other zones.
        # ** This syntax requires nginx version >=
        # ** 1.1.8. Cf. http://nginx.org/en/CHANGES. If using an older
        # ** version then use the limit_zone directive below
        # ** instead. Comment out this
        # ** one if not using nginx version >= 1.1.8.
        ###############################################################################	
	#				Anty DDOS			      	      #
	###############################################################################
	#Sets parameters for a shared memory zone that will keep states for various keys.
	#In particular, the state includes the current number of connections. 
	#The key can contain text, variables, and their combination. 
	#Requests with an empty key value are not accounted.
	 limit_conn_zone $binary_remote_addr zone=DDOS:10m;
	#The states are kept in a 10 megabyte zone “one”, and an average request processing rate for this zone cannot exceed 1 request per second.
 	#
	#A client IP address serves as a key. Note that instead of $remote_addr, the $binary_remote_addr variable is used here, that allows decreasing the state size down to 64 bytes. One megabyte zone can keep about 16 thousand 64-byte states.
	#If the zone storage is exhausted, the server will return the 503 (Service Temporarily Unavailable) error to all further requests.
	#
	#The rate is specified in requests per second (r/s). If a rate of less than one request per second is desired, it is specified in request per minute (r/m). 
	#For example, half-request per second is 30r/m.
         limit_req_zone  $binary_remote_addr  zone=one:10m   rate=50r/s;#1r used 
	#
         limit_req_zone  $uri  zone=two:10m   rate=200r/s;
	#allow a single range header for resumed downloads and to stop large range header DoS attacks
	  max_ranges                1; 
        ###############################################################################
        # Logfile Options (access log)
         access_log  /var/log/nginx/access.log  main; 
	  # to boost IO on HDD we can disable access logs
           #access_log off;
	###############################################################################
	#				Fastcgi,Fastcgi_Cache			      #
	###############################################################################
	#Caches information about open FDs, freqently accessed files.
        # can boost performance, but you need to test those values
        # Cache file metadata
        #http://nginx.org/en/docs/http/ngx_http_core_module.html#open_file_cache        
        #Default: [open_file_cache off;]
         open_file_cache max=100000 inactive=150s;
        #Sets a time after which open_file_cache elements should be validated.
        #Default: [open_file_cache_valid 60s;]
         open_file_cache_valid    160s;
        #Sets the minimum number of file accesses during the period configured by the inactive parameter of the open_file_cache directive, 
        #required for a file descriptor to remain open in the cache.
        #Default:[open_file_cache_min_uses 1;]
         open_file_cache_min_uses 5;
        #Enables or disables caching of file lookup errors by open_file_cache.
        #Default: [open_file_cache_errors off;]
         open_file_cache_errors   on;
	#Enables or disables adding comments to responses for MSIE clients with status greater than 400 to increase the response size to 512 bytes.
	#Default: [msie_padding on;]
	 msie_padding              off;
	#Fastcgi_Cache
	 fastcgi_cache_path /var/cache/nginxfastcgi levels=1:2 keys_zone=fastcgicache:60m inactive=60m max_size=1024m;
	 fastcgi_cache_key $scheme$request_method$host$request_uri;
	  # note: can also use HTTP headers to form the cache key, e.g.
	  #fastcgi_cache_key $scheme$request_method$host$request_uri$http_x_custom_header;
	   # note: can also use HTTP headers to form the cache key, e.g.
	   #fastcgi_cache_key $scheme$request_method$host$request_uri$http_x_custom_header;
	#When enabled, only one request at a time will be allowed to populate a new cache element identified according to the fastcgi_cache_key 
	#directive by passing a request to a FastCGI server. 
	#Other requests of the same cache element will either wait for a response to appear in the cache or 
	#the cache lock for this element to be released, up to the time set by the fastcgi_cache_lock_timeout directive.
	#Default: [fastcgi_cache_lock off;]
	 fastcgi_cache_lock on;
	#Determines in which cases a stale cached response can be used when an error occurs during communication with the FastCGI server. 
	#The directive’s parameters match the parameters of the fastcgi_next_upstream directive.
	#Syntax:fastcgi_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_503 | http_403 | http_404 | off ...;
	#Default: fastcgi_cache_use_stale off;
	 fastcgi_cache_use_stale error timeout invalid_header updating http_500;
	#Sets caching time for different response codes.
	#example: [fastcgi_cache_valid 200 302 10m;]
	 fastcgi_cache_valid 5m;
	#Disables processing of certain response header fields from the FastCGI server.
	 fastcgi_ignore_headers Cache-Control Expires Set-Cookie;
	# For Cache Testing Without Shutting Down PHP
 	 add_header rt-Fastcgi-Cache $upstream_cache_status;
	#Determines whether the connection with a FastCGI server should be closed when a client closes the connection without waiting for a response.
        # This directive determines if current request to the FastCGI-server must be aborted in case the client aborts the request to the server.
         #fastcgi_ignore_client_abort on;
	#Sets the number and size of the buffers used for reading a response from the FastCGI server, for a single connection. 
	#By default, the buffer size is equal to one memory page. 
	#This is either 4K or 8K, depending on a platform.
        #This directive sets the number and the size of the buffers into which the reply from the FastCGI process in the backend is read.
	#Default: [fastcgi_buffers 8 4k|8k;]
         fastcgi_buffers 256 32k; # 16k + 256 * 16k = 4112k total
	#Sets the size of the buffer used for reading the first part of the response received from the FastCGI server. 
	#This part usually contains a small response header. 
	#By default, the buffer size is equal to one memory page. 
	#This is either 4K or 8K, depending on a platform. 
	#It can be made smaller, however.
	#Default: [fastcgi_buffer_size 4k|8k]
         fastcgi_buffer_size 128k;
	#When buffering of responses from the FastCGI server is enabled, limits the total size of buffers that can be busy sending a response 
	#to the client while the response is not yet fully read. 
	#In the meantime, the rest of the buffers can be used for reading the response and, if needed, buffering part of the response to a temporary file. 
	#By default, size is limited by the size of two buffers set by the fastcgi_buffer_size and fastcgi_buffers directives.
	#Default:[fastcgi_busy_buffers_size 8k|16k;]
         fastcgi_busy_buffers_size 128k;
        #When buffering of responses from the FastCGI server is enabled, and the whole response does not fit into the buffers set by 
	#the fastcgi_buffer_size and fastcgi_buffers directives, a part of the response can be saved to a temporary file. 
	#This directive sets the maximum size of the temporary file. The size of data written to the temporary file at a time is set by the fastcgi_temp_file_write_size directive.
	# disable buffering to disk if replies start to exceeed your fastcgi buffers [if use 0]
	#Default:[fastcgi_max_temp_file_size 1024m;]
         fastcgi_max_temp_file_size 2048m;
	#Index
         fastcgi_index  index.php;
	#Defines a timeout for establishing a connection with a FastCGI server. It should be noted that this timeout cannot usually exceed 75 seconds.
	#Default: [fastcgi_connect_timeout 60s;]
         fastcgi_connect_timeout 120s;
        # allow 4 hrs - pass timeout responsibility to upstream
	#Defines a timeout for reading a response from the FastCGI server. 
	#The timeout is set only between two successive read operations, not for the transmission of the whole response. 
	#If the FastCGI server does not transmit anything within this time, the connection is closed.
	#Default:[fastcgi_read_timeout 60s;]
         fastcgi_read_timeout 14400;
        #Sets a timeout for transmitting a request to the FastCGI server. 
	#The timeout is set only between two successive write operations, not for the transmission of the whole request. 
	#If the FastCGI server does not receive anything within this time, the connection is closed.
	#Default: [fastcgi_send_timeout 60s;]
         fastcgi_send_timeout 180s;
        # This directive determines whether or not to transfer 4xx and 5xx errors back to the client or to allow Nginx to answer with directive error_page    .
         fastcgi_intercept_errors on;
        # When set to the value on, nginx will instruct a FastCGI server to keep connections open.
         fastcgi_keep_conn on; 
	###############################################################################
        #				Proxy and Cache Server			      #
	############################################################################### 
 	# PROXY/VARNISH Options
         # Put the Header that your varnish/proxy set
	  set_real_ip_from  0.0.0.0/0;
          #set_real_ip_from 127.0.0.1;
         #Add header for real_IP_from:
          real_ip_header X-Forwarded-For;
	#############
	#Use fastcgi_cache or proxy_cache
	 #proxy_redirect off;
  	 #proxy_set_header Host $host;
  	 #proxy_set_header X-Real-IP $remote_addr;
  	 #proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
  	# caching options
  	 proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my-cache:60m max_size=1000m inactive=600m;
	#
  	 proxy_temp_path /var/cache/tmp;
	#
	 proxy_cache_methods GET HEAD POST;
        ###############################################################################
	#					GZIP				      #
	###############################################################################
	#Add include file
      	 include global/gzip.conf;
	###############################################################################
        #					PAGESPEED			      #
	############################################################################### 
         #pagespeed on;
         #pagespeed FileCachePath              "/var/ngx_pagespeed_cache";
         #pagespeed FileCacheSizeKb            102400;
         #pagespeed FileCacheCleanIntervalMs   3600000;
         #pagespeed FileCacheInodeLimit        500000;
         #pagespeed FetchWithGzip on;
         #pagespeed EnableFilters combine_css,combine_javascript;
	############################################################################### 
	#					Map,upstream			      #			
	###############################################################################
        # If HTTPS, then set a variable so it can be passed along.
         map $scheme $server_https { 
	 #map $scheme $fastcgi_https {	
                                     default off;
                                     https on;
                                    }
        ## Add here all HTTP methods allowed
         map $request_method $bad_method {
          				       default 1;
          				       ~(?i)(GET|HEAD|POST) 0;
          				     }       
	# Upstream to abstract backend connection(s) for php
         upstream php-fpm {
           	            #this should match value of "listen" directive in php-fpm pool
     	            	    #server unix:/tmp/php-fpm.sock;
                    	    server 127.0.0.1:9000;
       	            	  }
	###############################################################################
    	# 				Virtual Host Configs			      #
	###############################################################################
     	#If you want, you could use it:
	 #include /etc/nginx/sites-enabled/*.conf;
    	# Virtual Host
     	 include /etc/nginx/conf.d/*.conf;
	###############################################################################	
}

